name: refresh data

on:
  workflow_dispatch:
  schedule:
    - cron: "17 6 * * 0"  # semanal (domingo 06:17 UTC)

permissions:
  contents: write

concurrency:
  group: refresh-data
  cancel-in-progress: false

jobs:
  refresh:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install deps
        run: |
          pip install -r requirements.txt
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi

      # -----------------------
      # OPIN (participants)
      # -----------------------
      - name: Build JSON (participants)
        run: python api/build_json.py
        env:
          OPIN_PARTICIPANTS_URL: "https://data.directory.opinbrasil.com.br/participants"

      - name: Validate participants.json (non-empty + meta.count > 0)
        run: |
          python - <<'PY'
          import json
          from pathlib import Path

          p = Path("api/v1/participants.json")
          if (not p.exists()) or p.stat().st_size < 10:
              raise SystemExit("ERRO: api/v1/participants.json ausente ou vazio. Abortando para não commitar lixo.")

          data = json.loads(p.read_text(encoding="utf-8"))
          count = int(data.get("meta", {}).get("count", 0))
          if count <= 0:
              raise SystemExit(f"ERRO: meta.count inválido ({count}). Abortando para não commitar.")
          print("OK: participants.json válido. meta.count =", count)
          PY

      - name: Validate FULL archives exist (participants raw + snapshot)
        run: |
          set -e
          test -s "data/raw/opin_participants_full.json.gz"
          ls -1 "data/snapshots"/opin_participants_full_*.json.gz >/dev/null
          latest="$(ls -1t data/snapshots/opin_participants_full_*.json.gz | head -n 1)"
          test -s "$latest"
          echo "OK: participants FULL archives present. Latest snapshot: $latest"

      - name: Guardrail SLIM size limit (participants)
        run: |
          python - <<'PY'
          from pathlib import Path
          p = Path("api/v1/participants.json")
          size = p.stat().st_size
          limit = 200_000  # 200 KB
          if size > limit:
              raise SystemExit(f"ERRO: participants.json inflou para {size} bytes (limite {limit}).")
          print("OK: participants.json size =", size)
          PY

      # -----------------------
      # SES (insurers) - B1
      # -----------------------
      - name: Build JSON (insurers)
        run: python api/build_insurers.py
        env:
          SES_ZIP_URL: "https://www2.susep.gov.br/safe/menuestatistica/ses/download/BaseCompleta.zip"

      - name: Validate insurers.json (non-empty + meta.count > 0 + items have data)
        run: |
          python - <<'PY'
          import json
          from pathlib import Path

          p = Path("api/v1/insurers.json")
          if (not p.exists()) or p.stat().st_size < 10:
              raise SystemExit("ERRO: api/v1/insurers.json ausente ou vazio. Abortando para não commitar lixo.")

          data = json.loads(p.read_text(encoding="utf-8"))
          count = int(data.get("meta", {}).get("count", 0))
          if count <= 0:
              raise SystemExit(f"ERRO: meta.count inválido ({count}). Abortando para não commitar.")

          # sanity: 5 primeiros têm 'data'
          for it in data.get("insurers", [])[:5]:
              if "data" not in it:
                  raise SystemExit("ERRO: item de insurers sem chave 'data' (schema antigo ainda está sendo gerado).")

          print("OK: insurers.json válido. meta.count =", count)
          PY

      - name: Validate FULL archives exist (insurers raw + snapshot)
        run: |
          set -e
          test -s "data/raw/insurers_full.json.gz"
          ls -1 "data/snapshots"/insurers_full_*.json.gz >/dev/null
          latest="$(ls -1t data/snapshots/insurers_full_*.json.gz | head -n 1)"
          test -s "$latest"
          echo "OK: insurers FULL archives present. Latest snapshot: $latest"

      - name: Guardrail: SLIM size limit (insurers)
        run: |
          python - <<'PY'
          from pathlib import Path
          p = Path("api/v1/insurers.json")
          size = p.stat().st_size
          limit = 1_500_000  # 1.5 MB (ajuste depois conforme crescerem campos)
          if size > limit:
              raise SystemExit(f"ERRO: insurers.json inflou para {size} bytes (limite {limit}).")
          print("OK: insurers.json size =", size)
          PY

      # -----------------------
      # Tests
      # -----------------------
      - name: Run tests
        run: pytest -q

      # -----------------------
      # Prune snapshots
      # -----------------------
      - name: Prune old snapshots (keep last 60)
        run: |
          find data/snapshots -maxdepth 1 -name 'opin_participants_full_*.json.gz' -printf '%T@ %p\n' \
            | sort -nr | awk 'NR>60 {print $2}' | xargs -r rm --
          find data/snapshots -maxdepth 1 -name 'insurers_full_*.json.gz' -printf '%T@ %p\n' \
            | sort -nr | awk 'NR>60 {print $2}' | xargs -r rm --

      # -----------------------
      # Commit
      # -----------------------
      - name: Commit changes (if any)
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add api/v1 data/raw data/snapshots

          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git commit -m "chore(data): refresh participants + insurers"
          git push
